{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing your dataset and keeping a log with `datascribe`\n",
    "\n",
    "For this example, we will load the example Emergency Department dataset, create a Scribe instance, and then preprocess the data via the Scribe instance so that it is ready for a logistic regression model.\n",
    "\n",
    "It will cover the methods for logging the following:\n",
    "\n",
    "* Imputing missing values\n",
    "* Scaling categorical data\n",
    "* Dummy coding categorical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path of the current script\n",
    "current_script_path = os.path.abspath(\"__file__\")\n",
    "\n",
    "# Deduce the root folder of the project\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_script_path)))\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `datascribe` imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load to access example dataset\n",
    "from datascribe.datasets import load_ed_example\n",
    "# import Scribe object from datascribe package\n",
    "from datascribe.scribe import Scribe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the Emergency Department (ED) Dataset example, taken from the NHS A&E Synthetic dataset available from [NHS England](https://nhsengland-direct-uploads.s3-eu-west-1.amazonaws.com/A%26E+Synthetic+Data.7z?versionId=null).  A little further information is available in the helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ED attendances example\n",
    "df = load_ed_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Scribe instance, specifying the output folder location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'output' already exists.\n"
     ]
    }
   ],
   "source": [
    "# specify folder directory\n",
    "file_loc = 'output'\n",
    "\n",
    "# define what the rows are called (singular, plural)\n",
    "row_description = (\"attendance\", \"attendances\")\n",
    "\n",
    "# create a Scribe object called s\n",
    "s = Scribe(df, dir=file_loc, row_descriptor=row_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it is worth reviewing the data frame information using `.info()` from **pandas**.\n",
    "\n",
    "For this example dataset, the data types were input when the csv file was read into the pandas Dataframe.  If you have not checked the data types of your dataset, it is best to check that the data types are accurate for the information you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106102 entries, 0 to 106101\n",
      "Data columns (total 13 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   IMD_Decile_From_LSOA             106075 non-null  Int8          \n",
      " 1   Age_Band                         106102 non-null  category      \n",
      " 2   Sex                              106071 non-null  category      \n",
      " 3   AE_Arrive_Date                   106102 non-null  datetime64[ns]\n",
      " 4   AE_Arrive_HourOfDay              106071 non-null  category      \n",
      " 5   AE_Time_Mins                     106102 non-null  Int32         \n",
      " 6   AE_HRG                           106100 non-null  category      \n",
      " 7   AE_Num_Diagnoses                 106102 non-null  Int32         \n",
      " 8   AE_Num_Investigations            106102 non-null  Int32         \n",
      " 9   AE_Num_Treatments                106102 non-null  Int32         \n",
      " 10  AE_Arrival_Mode                  106102 non-null  category      \n",
      " 11  Provider_Patient_Distance_Miles  106075 non-null  Float32       \n",
      " 12  Admitted_Flag                    106075 non-null  Int8          \n",
      "dtypes: Float32(1), Int32(4), Int8(2), category(5), datetime64[ns](1)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and managing null values in the dataset\n",
    "\n",
    "Null values need to be managed for the model.  Use **pandas**' `.isna().sum()` to check which columns contain nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMD_Decile_From_LSOA               27\n",
       "Age_Band                            0\n",
       "Sex                                31\n",
       "AE_Arrive_Date                      0\n",
       "AE_Arrive_HourOfDay                31\n",
       "AE_Time_Mins                        0\n",
       "AE_HRG                              2\n",
       "AE_Num_Diagnoses                    0\n",
       "AE_Num_Investigations               0\n",
       "AE_Num_Treatments                   0\n",
       "AE_Arrival_Mode                     0\n",
       "Provider_Patient_Distance_Miles    27\n",
       "Admitted_Flag                      27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output, we have four columns with missing values.\n",
    "\n",
    "There are several methods to filling missing values, which are available in the Scribe object's attribute `preprocessing`.  A few of them are demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing with the mean value\n",
    "#### *(Scribe.preprocessing.imputing_numeric_mean(df, columns=None))*\n",
    "\n",
    "`Provider_Patient_Distance_Miles` is a numerical field and advises us on how many miles the patient lives from the provider.  Here, we will use the mean value to imput missing values.\n",
    "\n",
    "`imputing_numeric_mean` in the `preprocessing` attribute of `Scribe` allows you to either transform all numeric items to the mean value if no columns specified, or a list of columns if input as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_mean = 'Provider_Patient_Distance_Miles'\n",
    "df = s.preprocessing.imputing_numeric_mean(df, cols_for_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to check that the values were imputed, you can recheck the null values for the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all null values replaced\n",
    "df[cols_for_mean].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the columns which have been imputed with this method by checking the `imputed_mean_cols` attribute within `preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Provider_Patient_Distance_Miles']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.preprocessing.imputed_mean_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to impute a column which has no null values, either because you have already immputed the values, or there were no missing values to begin with, you will receive a message to advise you.  However, if you try to impute a list of columns which contain some columns with missing values and some with no missing values, no message will appear but only the columns which were imputed will appear in `preprocessing.imputed_mean_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of the columns were imputed with the mean as there were no suitable columns or null values.\n"
     ]
    }
   ],
   "source": [
    "df = s.preprocessing.imputing_numeric_mean(df, cols_for_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing with the median value\n",
    "#### *(Scribe.preprocessing.imputing_numeric_median(df, columns=None))*\n",
    "\n",
    "`IMD_Decile_From_LSOA` is an integer data type and and indicates the deprivation decile of where the patient lives.  1 indicates the least deprived and 10 indicates the most deprived.\n",
    "\n",
    "While it is numerical, we cannot use the mean value as you cannot be between items on the scale.  Therefore, we will replace the values with the median value.\n",
    "\n",
    "Again, the method can process all numeric fields in the dataset or you can speficy which with the `columns` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_median = 'IMD_Decile_From_LSOA'\n",
    "df = s.preprocessing.imputing_numeric_median(df, cols_for_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all null values replaced\n",
    "df[cols_for_median].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing with the mode \n",
    "#### *(Scribe.preprocessing.imputing_numeric_mode(df, columns=None), Scribe.preprocessing.imputing_non_numeric_mode(df, columns=None))* \n",
    "\n",
    "For `Admitted_Flag`, we will use the mode to replace the missing values.  We will use the numeric method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_mode_num = 'Admitted_Flag'\n",
    "df = s.preprocessing.imputing_numeric_mode(df, cols_for_mode_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all null values replaced\n",
    "df[cols_for_mode_num].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will impute with the mode for the `AE_Arrive_HourOfDay` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mode_cat = 'AE_Arrive_HourOfDay'\n",
    "df = s.preprocessing.imputing_non_numeric_mode(df, cols_mode_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a separate method for non-numeric fields, which mainly differs from the above if you decide to replace all numerical or non-numerical fields in one go.  However, it is best practice to tailor the impute method for the specific fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing with constant value\n",
    "#### *(Scribe.preprocessing.imputing_non_numeric_constant(df, constant='missing', columns=None), Scribe.preprocessing.imputing_numeric_mode(df, constant=0, columns=None))*\n",
    "\n",
    "Similar to mode, there are two methods, `imputing_numeric_constant` and `imputing_non_numeric_constant` for either replacing all the fields with that data type with a fixed value, or a selection of columns.  Here, we will impute the column `Sex` with the default value for the non-numeric method, which is **missing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_constant = 'Sex'\n",
    "df = s.preprocessing.imputing_non_numeric_constant(df, columns=col_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all null values replaced\n",
    "df[col_constant].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the new value appears in the dataset by checking the column's unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1', 'missing']\n",
       "Categories (3, object): ['1', '2', 'missing']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will specify a constant value for `AE_HRG`, which will be *Nothing* (already a category in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = s.preprocessing.imputing_non_numeric_constant(df,\n",
    "                                                         constant='Nothing',\n",
    "                                                         columns='AE_HRG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check all the fields have no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMD_Decile_From_LSOA               0\n",
       "Age_Band                           0\n",
       "Sex                                0\n",
       "AE_Arrive_Date                     0\n",
       "AE_Arrive_HourOfDay                0\n",
       "AE_Time_Mins                       0\n",
       "AE_HRG                             0\n",
       "AE_Num_Diagnoses                   0\n",
       "AE_Num_Investigations              0\n",
       "AE_Num_Treatments                  0\n",
       "AE_Arrival_Mode                    0\n",
       "Provider_Patient_Distance_Miles    0\n",
       "Admitted_Flag                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other impute methods\n",
    "\n",
    "There are options as well to backfill and forward fill which work in the same way, but are not split into numeric and non-numeric options.\n",
    "\n",
    "#### *Scribe.preprocessing.imputing_backwardfill(df, columns=None)*\n",
    "\n",
    "#### *Scribe.preprocessing.imputing_forwardfill(df, columns=None)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that preprocessing steps have taken place\n",
    "\n",
    "#### *(Scribe.preprocessing.check_imputes_step())*\n",
    "\n",
    "You can check that values have been imputed via datascribe by using the checking method.  If any imput method has been successfully performed to replace values, it will return True.  Otherwise, it will return False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.preprocessing.check_imputes_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing the text summary\n",
    "\n",
    "#### (Scribe.preprocessing.imputing_commentary())\n",
    "\n",
    "With `imputing_commentary`, you can preview the text summary which would be prepared for the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Null values in Provider_Patient_Distance_Miles were imputed with the mean value. Null values in IMD_Decile_From_LSOA were imputed with the median value. Null values in Admitted_Flag and AE_Arrive_HourOfDay were imputed with the mode value. Null values in Sex and AE_HRG were imputed with the the following constant values: missing, Nothing.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.preprocessing.imputing_commentary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling categories which have an order\n",
    "\n",
    "#### *(Scribe.preprocessing.scale_categories(df, mappings, columns))*\n",
    "\n",
    "We will use the `scale_categories` method in `preprocessing` to turn a couple of the non-numeric fields into a scale so that this information is not lost in the model.\n",
    "\n",
    "While you can do this with just one column, we will process three columns at the same time using a list for the `columns` parameter and a list of dictionaries for the `mapppings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify columns\n",
    "cols_for_scaling = ['Age_Band', 'AE_Arrive_HourOfDay','AE_HRG']\n",
    "# specify mappings for above columns\n",
    "cols_scale_map = [{'1-17': 1, '18-24': 2,\n",
    "                   '45-64': 3, '25-44': 4,\n",
    "                   '65-84': 5, '85+': 6},\n",
    "                {'01-04': 1, '05-08': 2, '09-12': 3,\n",
    "                 '13-16': 4, '17-20': 5, '21-24': 6},\n",
    "                {'Nothing': 1, 'Low': 2, 'Medium': 3, 'High': 4}]\n",
    "# call method to scale\n",
    "df = s.preprocessing.scale_categories(df, cols_scale_map, cols_for_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we preview the columns, we can see they are now on a scale between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_Band</th>\n",
       "      <th>AE_Arrive_HourOfDay</th>\n",
       "      <th>AE_HRG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_Band  AE_Arrive_HourOfDay    AE_HRG\n",
       "0       0.6                  0.0  0.666667\n",
       "1       0.8                  0.6  0.666667\n",
       "2       0.6                  1.0  0.333333\n",
       "3       0.6                  0.8  0.666667\n",
       "4       0.2                  0.0  0.333333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols_for_scaling].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking whether any categorical scaling has taken place\n",
    "\n",
    "#### *(Scribe.preprocessing.check_cats_scaled())*\n",
    "\n",
    "You can check whether any categorical fields have been processed with this checker.  True means that it has taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.preprocessing.check_cats_scaled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling categories commentary\n",
    "\n",
    "#### *(Scribe.preprocessing.cat_scaling_commentary())*\n",
    "\n",
    "You can preview the summary text for scaling categories by using the `cat_scaling commentary` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The order of Age_Band, AE_Arrive_HourOfDay and AE_HRG were retained by mapping the order of the values and using the `MinMaxScaler()` method from the `sklearn` package to create a scale between 0 and 1.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.preprocessing.cat_scaling_commentary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical items\n",
    "\n",
    "#### *(Scribe.preprocessing.dummy_encoder(self, df, columns=None))*\n",
    "\n",
    "For categories which do not have an order of values to maintain, we can create dummies or 'one-hot encoding'.  Similar to other methods described above, if no columns are specified, the method will transform all fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_dummies = ['Sex', 'AE_Arrival_Mode']\n",
    "df = s.preprocessing.dummy_encoder(df, cols_for_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the new columns have been added to the data frame, and the original columns removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMD_Decile_From_LSOA</th>\n",
       "      <th>AE_Arrive_Date</th>\n",
       "      <th>AE_Time_Mins</th>\n",
       "      <th>AE_Num_Diagnoses</th>\n",
       "      <th>AE_Num_Investigations</th>\n",
       "      <th>AE_Num_Treatments</th>\n",
       "      <th>Provider_Patient_Distance_Miles</th>\n",
       "      <th>Admitted_Flag</th>\n",
       "      <th>Age_Band</th>\n",
       "      <th>AE_Arrive_HourOfDay</th>\n",
       "      <th>AE_HRG</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Sex_2</th>\n",
       "      <th>Sex_missing</th>\n",
       "      <th>AE_Arrival_Mode_0</th>\n",
       "      <th>AE_Arrival_Mode_1</th>\n",
       "      <th>AE_Arrival_Mode_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMD_Decile_From_LSOA AE_Arrive_Date  AE_Time_Mins  AE_Num_Diagnoses  \\\n",
       "0                     4     2016-08-30           150                 1   \n",
       "1                     3     2016-01-13           220                 1   \n",
       "2                     2     2016-04-28           160                 1   \n",
       "3                     4     2016-11-23           240                 1   \n",
       "4                     8     2016-09-03            60                 1   \n",
       "\n",
       "   AE_Num_Investigations  AE_Num_Treatments  Provider_Patient_Distance_Miles  \\\n",
       "0                      8                  4                              1.0   \n",
       "1                      8                  5                              0.0   \n",
       "2                      8                  4                              1.0   \n",
       "3                      8                  4                              4.0   \n",
       "4                      8                  3                              8.0   \n",
       "\n",
       "   Admitted_Flag  Age_Band  AE_Arrive_HourOfDay    AE_HRG  Sex_1  Sex_2  \\\n",
       "0              0       0.6                  0.0  0.666667  False   True   \n",
       "1              0       0.8                  0.6  0.666667  False   True   \n",
       "2              0       0.6                  1.0  0.333333   True  False   \n",
       "3              0       0.6                  0.8  0.666667   True  False   \n",
       "4              0       0.2                  0.0  0.333333  False   True   \n",
       "\n",
       "   Sex_missing  AE_Arrival_Mode_0  AE_Arrival_Mode_1  AE_Arrival_Mode_2  \n",
       "0        False              False               True              False  \n",
       "1        False              False              False               True  \n",
       "2        False              False              False               True  \n",
       "3        False              False              False               True  \n",
       "4        False              False               True              False  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to preview the draft write up which will be included in the output document, you can preview it by calling `Scribe.preprocessing.dummy_encoding_commentary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One-hot encoding was used on Sex and AE_Arrival_Mode using the pandas `get_dummies` method.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.preprocessing.dummy_encoding_commentary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the fields are now usable in the logistic regression model apart from the date field.  Currently, the package does not process this, so we will drop the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='AE_Arrive_Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106102 entries, 0 to 106101\n",
      "Data columns (total 16 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   IMD_Decile_From_LSOA             106102 non-null  Int8   \n",
      " 1   AE_Time_Mins                     106102 non-null  Int32  \n",
      " 2   AE_Num_Diagnoses                 106102 non-null  Int32  \n",
      " 3   AE_Num_Investigations            106102 non-null  Int32  \n",
      " 4   AE_Num_Treatments                106102 non-null  Int32  \n",
      " 5   Provider_Patient_Distance_Miles  106102 non-null  Float32\n",
      " 6   Admitted_Flag                    106102 non-null  Int8   \n",
      " 7   Age_Band                         106102 non-null  float64\n",
      " 8   AE_Arrive_HourOfDay              106102 non-null  float64\n",
      " 9   AE_HRG                           106102 non-null  float64\n",
      " 10  Sex_1                            106102 non-null  bool   \n",
      " 11  Sex_2                            106102 non-null  bool   \n",
      " 12  Sex_missing                      106102 non-null  bool   \n",
      " 13  AE_Arrival_Mode_0                106102 non-null  bool   \n",
      " 14  AE_Arrival_Mode_1                106102 non-null  bool   \n",
      " 15  AE_Arrival_Mode_2                106102 non-null  bool   \n",
      "dtypes: Float32(1), Int32(4), Int8(2), bool(6), float64(3)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final method in `preprocessing` is the `standardise_data` method, which will be used in the next notebook where the model is created."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-scribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
