# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/4A. S2A dataset preparation.ipynb.

# %% auto 0
__all__ = ['flac_to_s2a_name']

# %% ../nbs/4A. S2A dataset preparation.ipynb 2
import sys
import os
import itertools
from pathlib import Path

import numpy as np
import torch
import torchaudio
import torch.nn.functional as F
from torch.profiler import profile, record_function, ProfilerActivity

from fastprogress import progress_bar
from fastcore.script import *

import whisper
from . import vad, wh_transcribe, vq_stoks, extract_acoustic
import webdataset as wds

# %% ../nbs/4A. S2A dataset preparation.ipynb 5
def flac_to_s2a_name(input):
    if '-flac-' in input:
        return input.rsplit("/", 1)[1].replace('flac', 's2a') + ".gz"
    else:
        return input.rsplit("/", 1)[1].replace('raw', 's2a') + ".gz"

# %% ../nbs/4A. S2A dataset preparation.ipynb 7
def resampler(newsr = 24000, key = 'samples_24k'):
    _last_sr = None
    tform = None
    
    def _resample(samples):
        for s in samples:
            sr = s['sample_rate']
            if sr != newsr:
                if sr != _last_sr: tform = torchaudio.transforms.Resample(sr, newsr)
                s[key] = tform(s['samples'])
            else:
                s[key] = s['samples']
            yield s
    
    return _resample

# %% ../nbs/4A. S2A dataset preparation.ipynb 20
@call_parse
def prepare_s2a(
    input:str,  # FLAC webdataset file path (or - to read the names from stdin)
    proc_dataset_path:Path, # processed VAD files path
    output:str=None, # output file name
    vq_model:str="collabora/spear-tts-pytorch:whisper-vq-stoks.model", # the model path (use repo_id:filename to download it from hugginface)
    n_samples:int=None, # process a limited amount of samples
    batch_size:int=1, # process several segments at once
):
    if ":" in vq_model:
        repo, fname = vq_model.split(":", 1)
        vq_model = vq_stoks.RQBottleneckTransformer.load_model(repo, fname).cuda()
    else:
        vq_model = vq_stoks.RQBottleneckTransformer.load_model(local_filename=vq_model).cuda()
    amodel = extract_acoustic.load_model()
    amodel.set_target_bandwidth(3)
    
    from speechbrain.pretrained import EncoderClassifier
    spk_classifier = EncoderClassifier.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb", run_opts={"device": "cuda"})


    if input == "-":
        input = [f.strip() for f in sys.stdin.readlines()]
        assert output, "please provide the output shard name"
    else:
        if output is None: output = flac_to_s2a_name(input)
        input = [input]
        
    total = n_samples//batch_size if n_samples else 'noinfer'

    rename_files = vad.fix_dots_in_names if 'librilight' in input[0] else None
    ds = wds.WebDataset(input, rename_files=rename_files).compose(
        wds.decode(wds.torch_audio),
        vq_stoks.merge_in(vq_stoks.derived_dataset(proc_dataset_path, 'vad')),
        wds.map_dict(**{"vad.npy":wh_transcribe.chunk_merger}),
        wds.select(lambda x: 'wav' in x or 'flac' in x or 'mp3' in x or 'ogg' in x), # skip samples without audio
        wds.rename(audio="flac;mp3;wav;ogg"),
        lambda x: wh_transcribe.split_to_chunks(x),
        resampler(),
        resampler(16000, 'samples_16k'),
        wds.to_tuple('__key__', 'rpad_s', 'samples_16k', 'samples_24k'),
        wds.batched(64),
    )

    dl = wds.WebLoader(ds, num_workers=min(4, len(input)), batch_size=None).unbatched().batched(batch_size)

    tmp = output+".tmp"
    with wds.TarWriter(tmp) as sink:
        for keys, rpad_ss, samples, samples24k in progress_bar(dl, total=total):
            with record_function('to_cuda'):
                samples, samples24k = samples.cuda(), samples24k.unsqueeze(1).cuda()
            with record_function('encodec'):
                atoks = amodel.encode(samples24k)[0][0]
            with record_function('vq_stoks'):
                stoks = vq_model.encode_audio(samples)
            with record_function('spk_emb'):
                spk_embs = spk_classifier.encode_batch(
                   samples, wav_lens=torch.tensor(30 - rpad_ss, dtype=torch.float)/30)[:,0,:].cpu()
            with record_function('from_cuda'):
                atoks, stoks = atoks.cpu().numpy().astype(np.int16), stoks.cpu().numpy().astype(np.int16)
            for key, rpad_s, _atoks, _stoks, spk_emb in zip(keys, rpad_ss, atoks, stoks, spk_embs):
                _atoks = _atoks[:,:int((30-rpad_s) * 75)]
                _stoks = _stoks[:int((30-rpad_s) * 25)]
                sink.write({
                    "__key__": key,
                    "atoks.npy": _atoks,
                    "stoks.npy": _stoks,
                    "spk_emb.npy": spk_emb.numpy(),
                })
    if not n_samples:
        os.rename(tmp, output)
