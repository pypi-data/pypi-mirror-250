# Monte-Carlo-Neural-Nets

## Overview

A package made to see how well a basic architecture of neural nets could be. The nets can be created with custom input and output heights, as well as full customization of the hidden layers' sizes (height and count of layers) and activation functions that are applied at each space between the layers.

The basic operation of these nets is that they can be trained to some data set (or some score in an unsupervised case) by randomly 'tweaking' the different parameter weight values within the net. These weight values are clipped to be restrained to the range [-1, 1].

## GitHub and QuickStart
Given on the GitHub page below is a quick start code that shows the syntax for creating a network, a few ways to write in the activation functions to be used, the included train-test split function, fitting the models, getting their predictions, and the plots of the resulting predictions.

More explanations, examples, and technicals can be found on the GitHub page:
https://github.com/SciCapt/Monte-Carlo-Neural-Nets

