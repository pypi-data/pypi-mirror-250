#!/usr/bin/env python

from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import make_scorer, mean_squared_error
from datetime import datetime
import numpy as np
import os
try: 
    from sklearn.model_selection import GridSearchCV
except ImportError:
    from sklearn.grid_search import GridSearchCV

# List desired classificationa and regression models
num_procs = 20
model_names = ["Random Forest"]
condition_model_names = ["Random Forest"]
condition_model_objs = [RandomForestClassifier(n_estimators=500, max_features="sqrt", n_jobs=num_procs, min_samples_leaf=1)]

model_objs = [RandomForestClassifier(n_estimators=500, max_features="sqrt", max_depth=6, n_jobs=num_procs)]
dist_model_names = ["Random Forest"]
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)

dist_model_objs = [RandomForestRegressor(n_estimators=500, max_features="sqrt", n_jobs=num_procs, min_samples_leaf=1)]


#Desired varialbes, same as in the data preprocessing script.
storm_variables=['MAXUVV','Storm relative helicity_3000', 'Storm relative helicity_1000',
    		'MAXREF','MXUPHL_5000','MAXDVV']

potential_variables=['Precipitable water_0','Temperature_1000','Dew point temperature_1000','Geopotential Height_500','Temperature_500',
    'Dew point temperature_500','U component of wind_500','V component of wind_500',
    'Geopotential Height_700','Temperature_700', 'Dew point temperature_700','U component of wind_700',
    'V component of wind_700','Geopotential Height_850','Temperature_850', 'Dew point temperature_850',
    'U component of wind_850','V component of wind_850','MAXUW', 'MAXVW',
    'Surface lifted index','Convective available potential energy_0','Convective inhibition_0']

tendency_variables=[]
shape_variables=["area", "eccentricity", "major_axis_length", "minor_axis_length", "orientation"]

variable_statistics=["mean", "max", "min", "std",
                    "percentile_10", "percentile_50", "percentile_90"]
input_columns = []
for var in storm_variables:
    for stat in variable_statistics:
        input_columns.append(var + "_" + stat)
for var in potential_variables:
    for stat in variable_statistics:
        input_columns.append(var + "-potential_" + stat)
input_columns += shape_variables

ensemble_members = ['arw_00','arw_12','nssl_00','nssl_12','nmmb_00','nmmb_12','nam_00','nam_12']
scratch_path= "Path_to_hageslag_file_storage/"

fore_date = datetime.strptime(datetime.utcnow().strftime("%Y%m%d"), "%Y%m%d")

config=dict(ensemble_name="HREFv2",
            ensemble_members=ensemble_members,
            num_procs=num_procs,
            start_dates={"train": datetime(2017, 4, 1), "forecast": fore_date},
            end_dates={"train": datetime(2017, 7, 31), "forecast": fore_date},
            start_hour=12,
            end_hour=36,
            watershed_variable='MAXUVV',
            # Path to the pre-processed training data
            train_data_path='.../track_data_spring2017_MAXUVV_closest_csv/',
            forecast_data_path=scratch_path+'track_data_2019_MAXUVV_closest_csv/',
            #Path to the files containing information about ensemble members
            member_files={"train": ".../member_info_hrefv2_spring2018.csv",
                            "forecast": ".../member_info_hrefv2_spring2018.csv"},
            data_format="csv",
            group_col="Unique_Member", 
            condition_model_names=condition_model_names,
            condition_model_objs=condition_model_objs,
            condition_input_columns=input_columns,
            condition_output_column="Matched",
            condition_threshold=0.5,
            size_distribution_model_names=dist_model_names,
            size_distribution_model_objs=dist_model_objs,
            size_distribution_input_columns=input_columns,
            size_distribution_output_columns=["Shape", "Scale"],
            size_distribution_loc=19,
            load_models=True,
            #Path to the distribution of storm objects over full training period
            size_dis_training_path=scratch_path + 'HREFv2_2017_Size_Distribution/',
            #Path to trained ML models
            model_path=scratch_path + "track_models_MAXUVV_closest_spring2017/",
            metadata_columns=["Track_ID", "Step_ID", "Ensemble_Member", "Forecast_Hour"],
            data_json_path=scratch_path + "track_data_2019_MAXUVV_closest_json",
            forecast_json_path=scratch_path + "track_forecasts_2019_MAXUVV_closest_json/",
            forecast_csv_path=scratch_path + "track_forecasts_2019_MAXUVV_closest_csv/",
            netcdf_path=scratch_path+"track_data_2019_MAXUVV_patch_nc/",
            ensemble_variables=[],  
            ensemble_variable_thresholds={},
            ml_grid_method="gamma",
            neighbor_condition_model="Random Forest",
            neighbor_radius=[14],
            neighbor_sigma=[1],
            ensemble_consensus_path=scratch_path, 
            ensemble_data_path=scratch_path,
            model_map_file=".../hagelslag/mapfiles/hrefv2_2018_map.txt",
            ml_grid_percentiles=["mean", 90],
            grib_path=scratch_path + "hail_forecasts_grib2_hrefv2_closest_2019/",
            single_step=True,
            run_date_format="%Y%m%d-%H%M")
