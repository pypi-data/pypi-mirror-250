#!/usr/bin/env python
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import MultiTaskElasticNetCV
from sklearn.grid_search import GridSearchCV
from sklearn.metrics import make_scorer, mean_squared_error
from datetime import datetime
import os

date_dir = "/glade/scratch/wrfrt/realtime_ensemble/ensf/"
run_date_list = sorted(os.listdir(date_dir))
if "POST" in run_date_list:
    run_date_list.remove("POST")
run_dates = [datetime.strptime(r, "%Y%m%d%H") for r in run_date_list]
num_procs = 12
model_names = ["Random Forest"]
condition_model_objs = [GridSearchCV(RandomForestClassifier(n_estimators=500, 
                                                            class_weight="auto", 
                                                            n_jobs=num_procs,
                                                            min_samples_leaf=10),
                        param_grid=[dict(max_features=["sqrt", 20, 30, 50],
                        )],
                        scoring="roc_auc",
                        n_jobs=1)]
# Models for predicting a gamma size pdf
dist_model_names = ["Random Forest", "Elastic Net", "Random Forest CV"]
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
model_objs = [RandomForestClassifier(n_estimators=500, max_features=30, min_samples_leaf=10, n_jobs=num_procs)]
dist_model_objs = [RandomForestRegressor(n_estimators=500,
                                         min_samples_leaf=10,
                                         max_features="sqrt",
                                         n_jobs=num_procs),
                   MultiTaskElasticNetCV(l1_ratio=[0.1, 0.5, 0.9, 0.99], n_jobs=num_procs),
                   GridSearchCV(RandomForestRegressor(n_estimators=500, n_jobs=num_procs),
                                param_grid=[dict(max_features=["sqrt", 20, 30, 50],
                                                 min_samples_leaf=[5, 10, 30])],
                                scoring=mse_scorer,
                                n_jobs=1
                                ),
                   ]
storm_variables = ["UP_HELI_MAX", "GRPL_MAX", "W_UP_MAX", "W_DN_MAX", "HAIL_MAX2D", "HAIL_MAXK1",
                   "LTG3_MAX", "RVORT1_MAX", "UP_HELI_MAX03", "UP_HELI_MIN", "WSPD10MAX", "REFD_MAX"]
potential_variables = ["UBSHR1", "VBSHR1", "UBSHR6", "VBSHR6", "PWAT", "SRH3", "LCL_HEIGHT", "CAPE_SFC",
                       "CIN_SFC", "MUCAPE"]
tendency_variables=["UBSHR6", "VBSHR6", "REFD_MAX"]
shape_variables = ["area", "eccentricity", "major_axis_length", "minor_axis_length", "orientation",
                   "extent"]
variable_statistics=["mean", "max", "min", "std", "skew",
                     "percentile_10", "percentile_50", "percentile_90"]
# variables describing the shape of the object have been added
input_columns = ["Forecast_Hour", "Valid_Hour_UTC", "Duration_Step", "Duration_Total", "Storm_Motion_U", "Storm_Motion_V"]
for var in storm_variables:
    for stat in variable_statistics:
        input_columns.append(var + "_" + stat)
for var in potential_variables:
    for stat in variable_statistics:
        input_columns.append(var + "-potential_" + stat)
for var in tendency_variables:
    for stat in variable_statistics:
        input_columns.append(var + "-tendency_" + stat)
input_columns.extend(shape_variables)
print input_columns
# change the scratch path to your directory
scratch_path = "/glade/p/work/dgagne/"
ensemble_members = ["mem{0:d}".format(m) for m in range(1, 11)]
train_start = [datetime(2015,5,1), datetime(2015, 5, 15), datetime(2015,6,1), datetime(2015,6,15), datetime(2015,7,1)]
train_end = [datetime(2015,5,14), datetime(2015, 5, 31), datetime(2015,6,14), datetime(2015,6,30), datetime(2015,7,14)]
forecast_start = [run_dates[-1]]
forecast_end = [run_dates[-1]]
config = dict(ensemble_name="NCAR", # name of the ensemble; should match your data files
              ensemble_members=ensemble_members, # ensemble member list
              num_procs=num_procs, # number of processors; used in neighborhood probability generation
              start_dates={"train": train_start[0], "forecast": forecast_start[0]}, # beginning run dates
              end_dates={"train": train_end[-1], "forecast": forecast_end[0]}, # ending run dates
              start_hour=12, # first forecast hour
              end_hour=36, # last forecast hour
              map_filename="/glade/u/home/dgagne/hagelslag/mapfiles/ncar_ensemble_map_2015.txt",
              train_data_path=scratch_path + "track_data_ncar_2015_csv/",
              forecast_data_path=scratch_path + "track_data_ncar_2015_csv/",
              member_files={"train": scratch_path + "member_info_ncar_2015.csv",
                            "forecast": scratch_path + "member_info_ncar_2015.csv"},
              data_format="csv",
              group_col="Microphysics",
              condition_model_names=model_names,
              condition_model_objs=condition_model_objs,
              condition_input_columns=input_columns,
              condition_output_column="Hail_Size",
              condition_threshold=0.5,
              output_threshold=5,
              size_model_names=model_names,
              size_model_objs=model_objs,
              size_input_columns=input_columns,
              size_output_column="Hail_Size",
              size_range_params=(5, 100, 5),
              # Size distribution models predict the scale parameter of the gamma distribution
              # Then a linear regression is fitted between the log of the predicted scale parameter
              # and the log of the observed shape parameter.
              size_distribution_model_names=dist_model_names,
              size_distribution_model_objs=dist_model_objs,
              size_distribution_input_columns=input_columns,
              size_distribution_output_columns=["Shape", "Scale"],
              track_model_names=model_names,
              track_model_objs=model_objs,
              track_input_columns=input_columns,
              track_output_columns={"translation-x": "Translation_Error_X",
                                    "translation-y": "Translation_Error_Y",
                                    "start-time": "Start_Time_Error"},
              track_output_ranges={"translation-x": (-240000, 240000, 24000),
                                   "translation-y": (-240000, 240000, 24000),
                                   "start-time": (-6, 6, 1),
                                   },
              load_models=True,
              model_path=scratch_path + "track_models_ncar_2015/" + train_end[-1].strftime("%Y%m%d/"),
              metadata_columns=["Track_ID", "Step_ID"],
              data_json_path=scratch_path + "track_data_ncar_2015_json/",
              forecast_json_path=scratch_path + "track_forecasts_ncar_2015_json/",
              copula_file=scratch_path + "track_copulas_ncar_2015.pkl",
              num_track_samples=1000,
              sampler_thresholds=[25, 50],
              sampler_out_path=scratch_path + "track_samples_ncar_2015/", 
              neighbor_condition_model="Random Forest",
              # Variables used for generating neighborhood probabilities
              ensemble_variables=["HAIL_MAX2D", "HAIL_MAXK1", "UP_HELI_MAX", "GRPL_MAX"],
              # Neighborhood probability thresholds
              ensemble_variable_thresholds={"UP_HELI_MAX": [75, 150],
                                            "HAIL_MAXK1":[25, 50],
                                            "HAIL_MAX2D": [25, 50],
                                            "GRPL_MAX": [20, 40]},
              # Setting ml_grid_method as gamma will use the new models to generate the neighborhood probabilities
              # To use the bin models, set ml_grid_method="mean"
              ml_grid_method="gamma",
              neighbor_radius=[14, 28],
              neighbor_sigma=[5, 20],
              # Dimensions of the NCAR ensemble grid (y, x)
              grid_shape=(985, 1580),
              # Output path of neighborhood probability netCDF files.
              ensemble_consensus_path="/glade/scratch/dgagne/ensemble_consensus_ncar_2015/",
              # Path to ensemble data files
              ensemble_data_path="/glade/scratch/sobash/RT2015/",
              model_map_file="/glade/u/home/dgagne/hagelslag/mapfiles/ncar_ensemble_map_2015.txt",
              ml_grid_percentiles=["mean", 90],
              grib_path=scratch_path + "hail_forecasts_grib2_ncar_2015/",
              # If true, each model time step is stored in a separate netCDF file. False if they are grouped together.
              single_step=False,
              )
if not os.access(config["model_path"], os.R_OK):
    os.mkdir(config["model_path"])
