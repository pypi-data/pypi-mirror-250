Metadata-Version: 2.1
Name: pyntbci
Version: 0.2.4
Summary: Python Noise-Tagging Brain-Computer Interface (PyntBCI)
Home-page: https://gitlab.socsci.ru.nl/jthielen/pyntbci
Author: Jordy Thielen
Author-email: jordy.thielen@donders.ru.nl
License: BSD-3-Clause
Keywords: bci,cvep,eeg
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: BSD License
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: POSIX
Classifier: Operating System :: Unix
Classifier: Operating System :: MacOS
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: matplotlib>=3.7.2
Requires-Dist: numpy>=1.25.2
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: scipy>=1.11.1
Requires-Dist: setuptools>=57.0.0

# PyntBCI

Python Noise-Tagging Brain-Computer interface (PyntBCI) is a Python library for the noise-tagging brain-computer 
interface (BCI) project developed at the Donders Institute for Brain, Cognition and Behaviour, Radboud University, 
Nijmegen, the Netherlands. PyntBCI contains various signal processing steps and machine learning algorithms for BCIs 
that make use of evoked responses of the electroencephalogram (EEG), specifically code-modulated responses such as the 
code-modulated visual evoked potential (c-VEP). For a constructive review of this field, see [7].  

## Installation

To install PyntBCI, use:

	pip install pyntbci

## Getting started

Various tutorials and example analysis pipelines are provided in the `tutorials` and `examples/` folder, which operate 
on the datasets as provided below. 

## References

[1]: Thielen, J., van den Broek, P., Farquhar, J., & Desain, P. (2015). Broad-Band visually evoked potentials: 
re(con)volution in brain-computer interfacing. PLOS ONE, 10(7), e0133797. 
DOI: [10.1371/journal.pone.0133797](https://doi.org/10.1371/journal.pone.0133797)

[2]: Thielen, J., Marsman, P., Farquhar, J., & Desain, P. (2017). Re(con)volution: accurate response prediction for 
broad-band evoked potentials-based brain computer interfaces. In Brain-Computer Interface Research (pp. 35-42). 
Springer, Cham. DOI: [10.1007/978-3-319-64373-1_4](https://doi.org/10.1007/978-3-319-64373-1_4)

[3]: Desain, P. W. M., Thielen, J., van den Broek, P. L. C., & Farquhar, J. D. R. (2019). U.S. Patent No. 10,314,508. 
Washington, DC: U.S. Patent and Trademark Office. 
Link: [here](https://patentimages.storage.googleapis.com/40/a3/bb/65db00c7de99ec/US10314508.pdf)

[4]: Ahmadi, S., Borhanazad, M., Tump, D., Farquhar, J., & Desain, P. (2019). Low channel count montages using sensor 
tying for VEP-based BCI. Journal of Neural Engineering, 16(6), 066038. 
DOI: [10.1088/1741-2552/ab4057](https://doi.org/10.1088/1741-2552/ab4057)

[5]: Thielen, J., Marsman, P., Farquhar, J., & Desain, P. (2021). From full calibration to zero training for a 
code-modulated visual evoked potentials for brain–computer interface. Journal of Neural Engineering, 18(5), 056007. 
DOI: [10.1088/1741-2552/abecef](https://doi.org/10.1088/1741-2552/abecef)

[6]: Verbaarschot, C., Tump, D., Lutu, A., Borhanazad, M., Thielen, J., van den Broek, P., ... & Desain, P. (2021). A 
visual brain-computer interface as communication aid for patients with amyotrophic lateral sclerosis. Clinical 
Neurophysiology, 132(10), 2404-2415. DOI: [10.1016/j.clinph.2021.07.012](https://doi.org/10.1016/j.clinph.2021.07.012)

[7]: Martínez-Cagigal, V., Thielen, J., Santamaría-Vázquez, E., Pérez-Velasco, S., Desain, P., & Hornero, R. (2021). 
Brain–computer interfaces based on code-modulated visual evoked potentials (c-VEP): a literature review. Journal of 
Neural Engineering. DOI: [10.1088/1741-2552/ac38cf](https://doi.org/10.1088/1741-2552/ac38cf)

[8]: Thielen, J. (2023). Effects of Stimulus Sequences on Brain-Computer Interfaces Using Code-Modulated Visual 
Evoked Potentials: An Offline Simulation. In International Work-Conference on Artificial Neural Networks (pp. 555-568). 
Cham: Springer Nature Switzerland. DOI: [10.1007/978-3-031-43078-7_45](https://doi.org/10.1007/978-3-031-43078-7_45)

## Datasets

On the Radboud Data Repository (RDR) (https://data.ru.nl/):
* Thielen et al. (2018) Broad-Band Visually Evoked Potentials: Re(con)volution in Brain-Computer Interfacing. 
DOI: [10.34973/1ecz-1232](https://doi.org/10.34973/1ecz-1232)
* Ahmadi et al. (2018) High density EEG measurement. DOI: [10.34973/psaf-mq72](https://doi.org/10.34973/psaf-mq72)
* Ahmadi et al. (2019) Sensor tying. DOI: [10.34973/ehq6-b836](https://doi.org/10.34973/ehq6-b836)
* Thielen et al. (2021) From full calibration to zero training for a code-modulated visual evoked potentials brain 
  computer interface. DOI: [10.34973/9txv-z787](https://doi.org/10.34973/9txv-z787)

On Mother of all BCI Benchmarks (MOABB) (https://moabb.neurotechx.com/docs/index.html):
* [c-VEP dataset from Thielen et al. (2021)](
https://moabb.neurotechx.com/docs/generated/moabb.datasets.Thielen2021.html#moabb.datasets.Thielen2021)

## Contact

* Jordy Thielen (jordy.thielen@donders.ru.nl)

## Licensing

PyntBCI is licensed by the BSD 3-Clause License:

Copyright (c) 2021, Jordy Thielen
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

3. Neither the name of the copyright holder nor the names of its
   contributors may be used to endorse or promote products derived from
   this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# Changelog

## Version 0.2.4

### Added

- CCA cumulative/incremental average and covariance
- Amplitudes (e.g. envelopes) in structure matrix
- Maximum stopping time (`max_time`) for stopping methods
- brainamp64.loc
- A plt.show() in all examples

### Changed

### Fixed

- ITR calculation zero-division

## Version 0.2.3

### Added

### Changed

- Improved documentation
- Improved example pipelines
- Improved tutorial

### Fixed

## Version 0.2.2

### Added

- TRCA transformer
- eTRCA classifier
- Ensemble (`ensemble`) option (i.e., a spatial filter per class) for classifiers

### Changed

- Package name change of PyNT to PyntBCI
- Filterbank order optimized given parameters

### Fixed

- Issue causing novel events in M when "cutting cycles"
- Correlation does not change mutable input variables

## Version 0.2.1

### Added

- Tests
- Tutorial

### Changed

- Non-binary events for rCCA

### Fixed

## Version 0.2.0

### Added

- Dynamic stopping: margin, beta, Bayes
- Inner score metric

### Changed

- All data shapes: trials, channels, samples
- All codes shapes: classes, samples
- Changed all decision functions to similarity, not distance (e.g., Euclidean), to always maximize

### Fixed

- Zero-mean templates in eCCA and rCCA

## Version 0.1.0

### Added

- Filterbank classifier

### Changed

- Classifiers all have predict() and decision_function()

### Fixed

## Version 0.0.2

### Added

### Changed

- CCA method changed from sklearn to covariance method

### Fixed

## Version 0.0.1

### Added

- eCCA template metrics: average, median, OCSVM
- eCCA spatial filter options: all channels or subset

### Changed

### Fixed

## Version 0.0.0

### Added

- CCA transformer
- rCCA classifier
- eCCA classifier

### Changed

### Fixed
