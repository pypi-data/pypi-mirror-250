[LOCALE]
plugin.name = Llama-index (inline)
plugin.description = Integrates Llama-index storage in any chat and provides additional knowledge into context
prompt.label = Prompt
prompt.description = Prompt used for instruct how to use additional data provided from Llama-index
prompt.tooltip = Prompt
ask_llama_first.label = Ask Llama-index first
ask_llama_first.description = When enabled, then Llama-index will be asked first, and response will be used as additional knowledge in prompt. When disabled, then Llama-index will be asked only when needed.
ask_llama_first.tooltip = Ask Llama-index first
model_query.label = Model
model_query.description = Model used for querying Llama-index, default: gpt-3.5-turbo
model_query.tooltip = Model
idx.label = Index name
idx.description = Index to use, default: base, support for multiple indexes coming soon
idx.tooltip = Index name