{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting memoryprofiling_LBFGS.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile memoryprofiling_LBFGS.py\n",
    "\n",
    "from NuMPI.Optimization import LBFGS\n",
    "from tests.MPI_minimization_problems import MPI_Quadratic\n",
    "import numpy as np\n",
    "import scipy\n",
    "from NuMPI import MPI\n",
    "from NuMPI.Tools import Reduction\n",
    "from memory_profiler import profile\n",
    "import sys\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "nprocs= comm.Get_size()\n",
    "pnp = Reduction(comm)\n",
    "print(sys.argv)\n",
    "n= int(sys.argv[1])\n",
    "print(n)\n",
    "\n",
    "fp=open(\"LBFGS_memory_profile_n{}_nprocs{}_rank{}.log\".format(n, nprocs, rank), \"w\")\n",
    "LBFGS = profile(stream=fp)(LBFGS)\n",
    "\n",
    "Objective = MPI_Quadratic(n, pnp=pnp)\n",
    "result = LBFGS(Objective.f,Objective.startpoint(),\n",
    "                jac=Objective.grad,\n",
    "                options ={\"gtol\":1e-6,\"pnp\":Objective.pnp})\n",
    "fp.close()\n",
    "assert result.success\n",
    "print(result.nit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parse\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/c0/324d280a3298cdad806c3fb64eef31aed5c4dbd15b72a309498fb71c6a17/parse-1.12.0.tar.gz\n",
      "Building wheels for collected packages: parse\n",
      "  Building wheel for parse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/antoines/Library/Caches/pip/wheels/9f/62/d1/c46b7452aa0b2c838080bdd462110cd6c61890151f916aa743\n",
      "Successfully built parse\n",
      "Installing collected packages: parse\n",
      "Successfully installed parse-1.12.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import parse\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fn in glob(\"LBFGS_memory_profile_n*_nprocs*_rank*.log\"):\n",
    "    n, nprocs, rank = parse(\"LBFGS_memory_profile_n{:d}_nprocs{:d}_rank{:d}.log\", fn)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS_memory_profile_n10000000_nprocs2_rank0.log\r\n",
      "LBFGS_memory_profile_n10000000_nprocs2_rank1.log\r\n",
      "LBFGS_memory_profile_n1000000_nprocs2_rank0.log\r\n",
      "LBFGS_memory_profile_n1000000_nprocs2_rank1.log\r\n",
      "LBFGS_memory_profile_n100000_nprocs2_rank0.log\r\n",
      "LBFGS_memory_profile_n100000_nprocs2_rank1.log\r\n",
      "LBFGS_memory_profile_n10000_nprocs2_rank0.log\r\n",
      "LBFGS_memory_profile_n10000_nprocs2_rank1.log\r\n"
     ]
    }
   ],
   "source": [
    "ls *.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LBFGS_memory_profile_n10000_nprocs2_rank0.log'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = !sed -n -e  \"/^   [0-9]* [ ]*[0-9]*[.][0-9]* MiB/p\" {fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   109     55.8 MiB      0.0 MiB       if callback is None:\n",
      "   110     55.8 MiB      0.0 MiB           callback=donothing\n",
      "   113     55.8 MiB      0.0 MiB       if jac is True:\n",
      "   128     55.8 MiB      0.0 MiB       elif jac is False:\n",
      "   133     58.1 MiB      0.1 MiB           def fun_grad(x):\n",
      "   146     58.1 MiB      0.3 MiB               f = fun(x)\n",
      "   147     58.1 MiB      0.0 MiB               grad = jac(x).reshape((-1,1))\n",
      "   148     58.1 MiB      0.0 MiB               return f, grad\n",
      "   152     55.8 MiB      0.0 MiB       original_shape = x.shape\n",
      "   154     55.8 MiB      0.0 MiB       x = x.reshape((-1,1))\n",
      "   156     55.8 MiB      0.0 MiB       if x_old is None:\n",
      "   157     55.8 MiB      0.0 MiB           x_old = x.copy()\n",
      "   159     55.8 MiB      0.0 MiB               steepest_descent_wolfe2(x_old, fun_grad, pnp=pnp, maxiter=maxls,\n",
      "   160     56.3 MiB      0.0 MiB                                       **linesearch_options)\n",
      "   166     56.3 MiB      0.0 MiB       iterates = list()\n",
      "   167     56.3 MiB      0.0 MiB       k = 1\n",
      "   169     56.3 MiB      0.0 MiB       n = x.size  # number of degrees of freedom\n",
      "   170     56.3 MiB      0.0 MiB       gamma = 1\n",
      "   172     56.3 MiB      0.0 MiB       S = np.zeros((n, 0)) # history of the steps of x\n",
      "   173     56.3 MiB      0.0 MiB       Slist = []\n",
      "   174     56.3 MiB      0.0 MiB       Y = np.zeros((n, 0)) # history of gradient differences\n",
      "   175     56.3 MiB      0.0 MiB       Ylist = []\n",
      "   176     56.3 MiB      0.0 MiB       R = np.zeros((0, 0))\n",
      "   182     56.3 MiB      0.0 MiB       grad2 = pnp.sum(grad ** 2)\n",
      "   184     56.3 MiB      0.0 MiB       alpha = 0 #line search step size\n",
      "   188     56.3 MiB      0.0 MiB       while True:\n",
      "   191     58.1 MiB      0.0 MiB           if k > maxcor:\n",
      "   195     58.1 MiB      0.0 MiB               Slist[:-1] = Slist[1:]\n",
      "   196     58.1 MiB      0.0 MiB               Slist[-1] = (x - x_old)\n",
      "   201     58.1 MiB      0.0 MiB               Ylist[:-1] = Ylist[1:]\n",
      "   202     58.1 MiB      0.0 MiB               Ylist[-1] = (grad - grad_old)\n",
      "   206     57.6 MiB      0.0 MiB               Slist.append(x-x_old)\n",
      "   208     57.6 MiB      0.0 MiB               Ylist.append(grad - grad_old)\n",
      "   211     58.1 MiB      0.0 MiB           grad2prev = grad2\n",
      "   212     58.1 MiB      0.0 MiB           grad2 = pnp.sum(np.asarray(grad) ** 2)\n",
      "   219     58.1 MiB      0.0 MiB           callback(x)\n",
      "   221     58.1 MiB      0.0 MiB           if (pnp.max(np.abs(grad)) < gtol ):\n",
      "   233     58.1 MiB      0.0 MiB           if ((phi_old - phi)  <= ftol * max((1,abs(phi),abs(phi_old)))):\n",
      "   234     58.1 MiB      0.0 MiB               result = scipy.optimize.OptimizeResult({'success': True,\n",
      "   235     58.1 MiB      0.0 MiB                                                       'x': x.reshape(original_shape),\n",
      "   236     58.1 MiB      0.0 MiB                                                       'fun':phi,\n",
      "   237     58.1 MiB      0.0 MiB                                                       'jac': grad.reshape(original_shape),\n",
      "   238     58.1 MiB      0.0 MiB                                                       'nit': k,\n",
      "   239     58.1 MiB      0.0 MiB                                                       'message': 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH',\n",
      "   240     58.1 MiB      0.0 MiB                                                       'iterates': iterates})\n",
      "   243     58.1 MiB      0.0 MiB               return result\n",
      "   245     58.1 MiB      0.0 MiB           if k > maxiter:\n",
      "   258     58.1 MiB      0.0 MiB           STgrad = np.array([pnp.dot(si.T, grad) for si in Slist]).reshape(-1, 1)\n",
      "   259     58.1 MiB      0.0 MiB           YTgrad = np.array([pnp.dot(yi.T, grad) for yi in Ylist]).reshape(-1, 1)\n",
      "   263     58.1 MiB      0.0 MiB           if k > maxcor:\n",
      "   265     58.1 MiB      0.0 MiB               S_now_T_grad_prev = np.roll(STgrad_prev,-1)\n",
      "   266     58.1 MiB      0.0 MiB               S_now_T_grad_prev[-1] = - alpha * gamma * grad2prev - alpha * (STgrad_prev.T.dot(p1) + gamma * YTgrad_prev.T.dot(p2))\n",
      "   268     57.6 MiB      0.0 MiB               S_now_T_grad_prev = np.array([pnp.dot(si.T, grad_old) for si in Slist]).reshape(-1, 1)\n",
      "   271     58.1 MiB      0.0 MiB           if k > maxcor:\n",
      "   272     58.1 MiB      0.0 MiB               R = np.roll(R, (-1, -1), axis=(0, 1))  # mxm Matrix hold by all Processors\n",
      "   273     58.1 MiB      0.0 MiB               R[-1, :] = 0\n",
      "   274     58.1 MiB      0.0 MiB               STym1 = STgrad - S_now_T_grad_prev\n",
      "   275     58.1 MiB      0.0 MiB               R[:, -1] = STym1.flat  #O(m x n)\n",
      "   277     57.6 MiB      0.0 MiB           elif k == 1:\n",
      "   279     56.4 MiB      0.0 MiB               R = np.triu(np.array([[pnp.dot(si.T, yi).item() for yi in Ylist] for si in Slist]))\n",
      "   284     57.6 MiB      0.0 MiB               R = np.vstack([R, np.zeros(k - 1)])\n",
      "   285     57.6 MiB      0.0 MiB               R = np.hstack([R, np.array([pnp.dot(si.T, Ylist[-1]) for si in Slist]).reshape(k, 1)])\n",
      "   286     58.1 MiB      0.0 MiB           if k > maxcor:\n",
      "   287     58.1 MiB      0.0 MiB               D = np.roll(D, (-1, -1), axis=(0, 1))\n",
      "   289     58.1 MiB      0.0 MiB               D[-1, -1] = R[-1,-1]\n",
      "   292     57.6 MiB      0.0 MiB               D = np.diag(R.diagonal())\n",
      "   293     58.1 MiB      0.0 MiB           assert D[-1,-1] > 0, \"k = {}: \".format(k)  # Assumption of Theorem 2.2\n",
      "   295     58.1 MiB      0.0 MiB           if k > maxcor:\n",
      "   296     58.1 MiB      0.0 MiB               YTY = np.roll(YTY, (-1, -1), axis=(0, 1))\n",
      "   297     58.1 MiB      0.0 MiB               YTY[-1, :-1] = YTY[:-1, -1] = (YTgrad[:-1] - YTgrad_prev[1:]).flat\n",
      "   298     58.1 MiB      0.0 MiB               YTY[-1, -1] = grad2prev - grad2 + 2 * YTgrad[-1]\n",
      "   301     57.6 MiB      0.0 MiB               YTY = np.array([[pnp.dot(yi1.T, yi2).item() for yi2 in Ylist] for yi1 in Ylist])\n",
      "   303     58.1 MiB      0.0 MiB           gamma = D[-1, -1] / YTY[-1, -1]  # n.b. D[-1,-1] = sk-1T yk-1 = yk-1T sk-1\n",
      "   306     58.1 MiB      0.1 MiB           Rinv = np.linalg.inv(R)\n",
      "   307     58.1 MiB      0.0 MiB           RiSg = Rinv.dot(STgrad)\n",
      "   308     58.1 MiB      0.0 MiB           p1 = Rinv.T.dot(D + gamma * YTY).dot(RiSg) - gamma * Rinv.T.dot(YTgrad)\n",
      "   309     58.1 MiB      0.0 MiB           p2 = - RiSg #TODO\n",
      "   314     58.1 MiB      0.0 MiB           Hgrad = gamma * grad\n",
      "   315     58.1 MiB      0.0 MiB           for si, yi, p1i, p2i in zip(Slist, Ylist, p1.flat, p2.flat):\n",
      "   316     58.1 MiB      0.1 MiB               Hgrad += si * p1i.item() + gamma * yi * p2i.item()\n",
      "   318     58.1 MiB      0.0 MiB           phi_old = float(phi)\n",
      "   320     58.1 MiB      0.0 MiB           grad_old[:] = grad\n",
      "   321     58.1 MiB      0.0 MiB           x_old[:] = x\n",
      "   322     58.1 MiB      0.0 MiB           def _phi_phiprime(alpha):\n",
      "   323     58.1 MiB      0.0 MiB               phi, grad[...] = fun_grad(x - Hgrad * alpha)\n",
      "   324     58.1 MiB      0.0 MiB               phiprime = pnp.dot(grad.T, -Hgrad).item()\n",
      "   325     58.1 MiB      0.0 MiB               return phi, phiprime\n",
      "   328     58.1 MiB      0.0 MiB           alpha, phi, phi0, derphi = scalar_search_wolfe2(_phi_phiprime, phi0=phi,\n",
      "   329     58.1 MiB      0.0 MiB                                                           derphi0=pnp.dot(grad.T, -Hgrad).item(), maxiter=maxls, **linesearch_options)\n",
      "   331     58.1 MiB      0.0 MiB           printdb(\"derphi: {}\".format(derphi))\n",
      "   332     58.1 MiB      0.0 MiB           assert derphi is not None, \"line-search did not converge\"\n",
      "   335     58.1 MiB      0.0 MiB           x = x - Hgrad * alpha\n",
      "   337     58.1 MiB      0.0 MiB           if store_iterates == 'iterate':\n",
      "   344     58.1 MiB      0.0 MiB           printdb(\"k = {}\".format(k))\n",
      "   345     58.1 MiB      0.0 MiB           k = k + 1\n",
      "   347     58.1 MiB      0.0 MiB           STgrad_prev = STgrad.copy()\n",
      "   348     58.1 MiB      0.0 MiB           YTgrad_prev = YTgrad.copy()\n"
     ]
    }
   ],
   "source": [
    "fn=\"LBFGS_memory_profile_n10000000_nprocs2_rank0.log\"\n",
    "import re \n",
    "expr = re.compile(r\"^\\s*([0-9]*) [0-9]* [ ]*([0-9]*[.][0-9]*) MiB[ ]*([0-9]*[.][0-9]*) MiB [ ]*(.*)$\" )\n",
    "for line in text:\n",
    "    print(line)\n",
    "    ln, memusage, memincr, code = expr.match(line).groups()\n",
    "    row = pd.DataFrame.from_records(dict(\n",
    "    linenumber=[int(ln)], \n",
    "    mem_usage=float(memusage), \n",
    "    mem_incr=float(memincr), \n",
    "    code=code\n",
    "    ),)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lnb, memuse, memincr = parse(\"{:d} {:f} MiB {:f} MiB {:s} \", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('348', '58.1', '0.0', 'YTgrad_prev = YTgrad.copy()')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/antoines/NuMPI/NuMPI/Optimization/MPI_LBFGS_Matrix_H.py\r\n",
      "\r\n",
      "Line #    Mem usage    Increment   Line Contents\r\n",
      "================================================\r\n",
      "    68     55.8 MiB     55.8 MiB   def LBFGS(fun, x, args=(), jac=None, x_old=None, maxcor=10, gtol = 1e-5, ftol=2.2e-9, maxiter=15000,\r\n",
      "    69                                       maxls=20, linesearch_options=dict(c1=1e-3, c2=0.9), pnp=Reduction(MPI.COMM_WORLD),\r\n",
      "    70                                       store_iterates=None, printdb=donothing, callback=None, **options):\r\n",
      "    71                                 \"\"\"\r\n",
      "    72                             \r\n",
      "    73                                 convergence if |grad|_{\\infty} <= gtol or <= ftol is satisfied\r\n",
      "    74                             \r\n",
      "    75                                 Parameters\r\n",
      "    76                                 ----------\r\n",
      "    77                                 fun\r\n",
      "    78                                 x\r\n",
      "    79                                 args\r\n",
      "    80                                 jac\r\n",
      "    81                                 x_old: initial guess\r\n",
      "    82                                 maxcor: max number of history gradients stored\r\n",
      "    83                                 gtol:\r\n",
      "    84                                 ftol:\r\n",
      "    85                                 maxiter\r\n",
      "    86                                 maxls, default 20, as in scipy.optimize.fmin_l_bfgs_b\r\n",
      "    87                                 linesearch_options: further options for the linesearch\r\n",
      "    88                                 the result of the linesearch has to satisfy the strong wolfe condition\r\n",
      "    89                                 See Wright and Nocedal, 'Numerical Optimization',p.34\r\n",
      "    90                                 c1 parameter for the sufficient decrease condition\r\n",
      "    91                                 c2 parameter for the curvature condition\r\n",
      "    92                                 \r\n",
      "    93                                 default values are choosen here to match the implementation in\r\n",
      "    94                                 the Fortran subroutine L-BFGS-B 3.0 by\r\n",
      "    95                                 Ciyou Zhu, Richard Byrd, and Jorge Nocedal\r\n",
      "    96                             \r\n",
      "    97                                 See lbfgsb.f line 2497, with gtol=c2 and ftol=c1\r\n",
      "    98                                 \r\n",
      "    99                                 pnp\r\n",
      "   100                                 store_iterates: stores each iterate of x, only debugging\r\n",
      "   101                                 printdb\r\n",
      "   102                                 options\r\n",
      "   103                             \r\n",
      "   104                                 Returns\r\n",
      "   105                                 -------\r\n",
      "   106                             \r\n",
      "   107                                 \"\"\"\r\n",
      "   108                             \r\n",
      "   109     55.8 MiB      0.0 MiB       if callback is None:\r\n",
      "   110     55.8 MiB      0.0 MiB           callback=donothing\r\n",
      "   111                             \r\n",
      "   112                                 #print(\"jac = {}, type = {}\".format(jac, type(jac)))\r\n",
      "   113     55.8 MiB      0.0 MiB       if jac is True:\r\n",
      "   114                                     def fun_grad(x):\r\n",
      "   115                                         \"\"\"\r\n",
      "   116                                         reshapes the gradient in a convenient form\r\n",
      "   117                                         Parameters\r\n",
      "   118                                         ----------\r\n",
      "   119                                         x\r\n",
      "   120                             \r\n",
      "   121                                         Returns\r\n",
      "   122                                         -------\r\n",
      "   123                             \r\n",
      "   124                                         \"\"\"\r\n",
      "   125                                         f, grad = fun(x)\r\n",
      "   126                                         return f, grad.reshape((-1,1))\r\n",
      "   127                             \r\n",
      "   128     55.8 MiB      0.0 MiB       elif jac is False:\r\n",
      "   129                                     raise NotImplementedError(\"Numerical evaluation of gradient not implemented\")\r\n",
      "   130                                 else:\r\n",
      "   131                                     # function and gradient provided sepatately\r\n",
      "   132                             \r\n",
      "   133     58.1 MiB      0.1 MiB           def fun_grad(x):\r\n",
      "   134                                         \"\"\"\r\n",
      "   135                                         evaluates function and grad consequently (important, see issue #13)\r\n",
      "   136                                         and reshapes the gradient in a convenient form\r\n",
      "   137                                         Parameters\r\n",
      "   138                                         ----------\r\n",
      "   139                                         x\r\n",
      "   140                             \r\n",
      "   141                                         Returns\r\n",
      "   142                                         -------\r\n",
      "   143                             \r\n",
      "   144                                         \"\"\"\r\n",
      "   145                                         # order matte\r\n",
      "   146     58.1 MiB      0.3 MiB               f = fun(x)\r\n",
      "   147     58.1 MiB      0.0 MiB               grad = jac(x).reshape((-1,1))\r\n",
      "   148     58.1 MiB      0.0 MiB               return f, grad\r\n",
      "   149                             \r\n",
      "   150                                 # user can provide x in the shape of his convenience\r\n",
      "   151                                 # but we will work with the shape (-1, 1)\r\n",
      "   152     55.8 MiB      0.0 MiB       original_shape = x.shape\r\n",
      "   153                             \r\n",
      "   154     55.8 MiB      0.0 MiB       x = x.reshape((-1,1))\r\n",
      "   155                             \r\n",
      "   156     55.8 MiB      0.0 MiB       if x_old is None:\r\n",
      "   157     55.8 MiB      0.0 MiB           x_old = x.copy()\r\n",
      "   158                                     x, grad, x_old, grad_old, phi, phi_old, derphi = \\\r\n",
      "   159     55.8 MiB      0.0 MiB               steepest_descent_wolfe2(x_old, fun_grad, pnp=pnp, maxiter=maxls,\r\n",
      "   160     56.3 MiB      0.0 MiB                                       **linesearch_options)\r\n",
      "   161                                 else:\r\n",
      "   162                                     phi_old, grad_old = fun_grad(x_old) # phi_old is never used, except for the convergence criterion\r\n",
      "   163                                     phi, grad = fun_grad(x)\r\n",
      "   164                             \r\n",
      "   165                                 # full history of x is sored here if wished\r\n",
      "   166     56.3 MiB      0.0 MiB       iterates = list()\r\n",
      "   167     56.3 MiB      0.0 MiB       k = 1\r\n",
      "   168                             \r\n",
      "   169     56.3 MiB      0.0 MiB       n = x.size  # number of degrees of freedom\r\n",
      "   170     56.3 MiB      0.0 MiB       gamma = 1\r\n",
      "   171                             \r\n",
      "   172     56.3 MiB      0.0 MiB       S = np.zeros((n, 0)) # history of the steps of x\r\n",
      "   173     56.3 MiB      0.0 MiB       Slist = []\r\n",
      "   174     56.3 MiB      0.0 MiB       Y = np.zeros((n, 0)) # history of gradient differences\r\n",
      "   175     56.3 MiB      0.0 MiB       Ylist = []\r\n",
      "   176     56.3 MiB      0.0 MiB       R = np.zeros((0, 0))\r\n",
      "   177                                 #STgrad = np.array((1, maxcor))\r\n",
      "   178                                 #YTgrad = np.array((1, maxcor))\r\n",
      "   179                                 #STgrad_prev = STgrad.copy()  # TODO: preallocate\r\n",
      "   180                                 #YTgrad_prev = YTgrad.copy()\r\n",
      "   181                             \r\n",
      "   182     56.3 MiB      0.0 MiB       grad2 = pnp.sum(grad ** 2)\r\n",
      "   183                             \r\n",
      "   184     56.3 MiB      0.0 MiB       alpha = 0 #line search step size\r\n",
      "   185                             \r\n",
      "   186                                 # Start loop\r\n",
      "   187                                 #printdb(k)\r\n",
      "   188     56.3 MiB      0.0 MiB       while True:\r\n",
      "   189                                     # Update Sk,Yk\r\n",
      "   190                                     #print(\"k= {}\".format(k))\r\n",
      "   191     58.1 MiB      0.0 MiB           if k > maxcor:\r\n",
      "   192                                         #S = np.roll(S, -1)\r\n",
      "   193                                         #S[:, -1] = (x - x_old).flat\r\n",
      "   194                             \r\n",
      "   195     58.1 MiB      0.0 MiB               Slist[:-1] = Slist[1:]\r\n",
      "   196     58.1 MiB      0.0 MiB               Slist[-1] = (x - x_old)\r\n",
      "   197                             \r\n",
      "   198                                         #Y = np.roll(Y, -1)\r\n",
      "   199                                         #Y[:, -1] = (grad - grad_old).flat\r\n",
      "   200                             \r\n",
      "   201     58.1 MiB      0.0 MiB               Ylist[:-1] = Ylist[1:]\r\n",
      "   202     58.1 MiB      0.0 MiB               Ylist[-1] = (grad - grad_old)\r\n",
      "   203                             \r\n",
      "   204                                     else:\r\n",
      "   205                                         #S = np.hstack([S, x - x_old])\r\n",
      "   206     57.6 MiB      0.0 MiB               Slist.append(x-x_old)\r\n",
      "   207                                         #Y = np.hstack([Y, grad - grad_old])\r\n",
      "   208     57.6 MiB      0.0 MiB               Ylist.append(grad - grad_old)\r\n",
      "   209                             \r\n",
      "   210                                     # 2.\r\n",
      "   211     58.1 MiB      0.0 MiB           grad2prev = grad2\r\n",
      "   212     58.1 MiB      0.0 MiB           grad2 = pnp.sum(np.asarray(grad) ** 2)\r\n",
      "   213                             \r\n",
      "   214                                     ######################\r\n",
      "   215                                     # check if job is done\r\n",
      "   216                                     #if ((grad2 < g2tol if g2tol is not None else True) and\r\n",
      "   217                                     #        (pnp.max(np.abs(grad)) < gtol if gtol is not None else True) and\r\n",
      "   218                                     #        ((phi - phi_old) / max((1,abs(phi),abs(phi_old))) <= ftol if ftol is not None else True)):\r\n",
      "   219     58.1 MiB      0.0 MiB           callback(x)\r\n",
      "   220                             \r\n",
      "   221     58.1 MiB      0.0 MiB           if (pnp.max(np.abs(grad)) < gtol ):\r\n",
      "   222                                         result = scipy.optimize.OptimizeResult({'success': True,\r\n",
      "   223                                                                                 'x': x.reshape(original_shape),\r\n",
      "   224                                                                                 'fun':phi,\r\n",
      "   225                                                                                 'jac': grad.reshape(original_shape),\r\n",
      "   226                                                                                 'nit': k,\r\n",
      "   227                                                                                 'message': 'CONVERGENCE: NORM_OF_GRADIENT_<=_GTOL',\r\n",
      "   228                                                                                 'iterates': iterates})\r\n",
      "   229                                         # if iterates:\r\n",
      "   230                                         #    result['iterates'] = iterates\r\n",
      "   231                                         return result\r\n",
      "   232                             \r\n",
      "   233     58.1 MiB      0.0 MiB           if ((phi_old - phi)  <= ftol * max((1,abs(phi),abs(phi_old)))):\r\n",
      "   234     58.1 MiB      0.0 MiB               result = scipy.optimize.OptimizeResult({'success': True,\r\n",
      "   235     58.1 MiB      0.0 MiB                                                       'x': x.reshape(original_shape),\r\n",
      "   236     58.1 MiB      0.0 MiB                                                       'fun':phi,\r\n",
      "   237     58.1 MiB      0.0 MiB                                                       'jac': grad.reshape(original_shape),\r\n",
      "   238     58.1 MiB      0.0 MiB                                                       'nit': k,\r\n",
      "   239     58.1 MiB      0.0 MiB                                                       'message': 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH',\r\n",
      "   240     58.1 MiB      0.0 MiB                                                       'iterates': iterates})\r\n",
      "   241                                         # if iterates:\r\n",
      "   242                                         #    result['iterates'] = iterates\r\n",
      "   243     58.1 MiB      0.0 MiB               return result\r\n",
      "   244                             \r\n",
      "   245     58.1 MiB      0.0 MiB           if k > maxiter:\r\n",
      "   246                                         result = scipy.optimize.OptimizeResult({'success': False,\r\n",
      "   247                                                                                 'x': x.reshape(original_shape),\r\n",
      "   248                                                                                 'fun':phi,\r\n",
      "   249                                                                                 'jac': grad.reshape(original_shape),\r\n",
      "   250                                                                                 'nit': k,\r\n",
      "   251                                                                                 'iterates': iterates})\r\n",
      "   252                             \r\n",
      "   253                                         return result\r\n",
      "   254                                     ###########\r\n",
      "   255                                     # new iteration\r\n",
      "   256                             \r\n",
      "   257                             \r\n",
      "   258     58.1 MiB      0.0 MiB           STgrad = np.array([pnp.dot(si.T, grad) for si in Slist]).reshape(-1, 1)\r\n",
      "   259     58.1 MiB      0.0 MiB           YTgrad = np.array([pnp.dot(yi.T, grad) for yi in Ylist]).reshape(-1, 1)\r\n",
      "   260                                     #STgrad = pnp.dot(S.T, grad)\r\n",
      "   261                                     #YTgrad = pnp.dot(Y.T, grad)\r\n",
      "   262                             \r\n",
      "   263     58.1 MiB      0.0 MiB           if k > maxcor:\r\n",
      "   264                                         #w = np.vstack([STgrad_prev, gamma * YTgrad_prev]) #TODO: vstack\r\n",
      "   265     58.1 MiB      0.0 MiB               S_now_T_grad_prev = np.roll(STgrad_prev,-1)\r\n",
      "   266     58.1 MiB      0.0 MiB               S_now_T_grad_prev[-1] = - alpha * gamma * grad2prev - alpha * (STgrad_prev.T.dot(p1) + gamma * YTgrad_prev.T.dot(p2))\r\n",
      "   267                                     else : # straightforward Version\r\n",
      "   268     57.6 MiB      0.0 MiB               S_now_T_grad_prev = np.array([pnp.dot(si.T, grad_old) for si in Slist]).reshape(-1, 1)\r\n",
      "   269                             \r\n",
      "   270                             \r\n",
      "   271     58.1 MiB      0.0 MiB           if k > maxcor:\r\n",
      "   272     58.1 MiB      0.0 MiB               R = np.roll(R, (-1, -1), axis=(0, 1))  # mxm Matrix hold by all Processors\r\n",
      "   273     58.1 MiB      0.0 MiB               R[-1, :] = 0\r\n",
      "   274     58.1 MiB      0.0 MiB               STym1 = STgrad - S_now_T_grad_prev\r\n",
      "   275     58.1 MiB      0.0 MiB               R[:, -1] = STym1.flat  #O(m x n)\r\n",
      "   276                             \r\n",
      "   277     57.6 MiB      0.0 MiB           elif k == 1:\r\n",
      "   278                                         #Rm = np.triu(pnp.dot(S.T, Y))\r\n",
      "   279     56.4 MiB      0.0 MiB               R = np.triu(np.array([[pnp.dot(si.T, yi).item() for yi in Ylist] for si in Slist]))\r\n",
      "   280                                         #print(R)\r\n",
      "   281                                     else:\r\n",
      "   282                                         #Rm = np.vstack([Rm, np.zeros(k - 1)])\r\n",
      "   283                                         #Rm = np.hstack([Rm, pnp.dot(S.T, Y[:, -1]).reshape(k, 1)])\r\n",
      "   284     57.6 MiB      0.0 MiB               R = np.vstack([R, np.zeros(k - 1)])\r\n",
      "   285     57.6 MiB      0.0 MiB               R = np.hstack([R, np.array([pnp.dot(si.T, Ylist[-1]) for si in Slist]).reshape(k, 1)])\r\n",
      "   286     58.1 MiB      0.0 MiB           if k > maxcor:\r\n",
      "   287     58.1 MiB      0.0 MiB               D = np.roll(D, (-1, -1), axis=(0, 1))\r\n",
      "   288                                         # D[-1,-1] = np.dot(Y[:,-1],Y[:,-1])# yk-1Tyk-1 # TOOPTIMIZE\r\n",
      "   289     58.1 MiB      0.0 MiB               D[-1, -1] = R[-1,-1]\r\n",
      "   290                                     else:\r\n",
      "   291                                         #D = np.diag(np.einsum(\"ik,ik -> k\", S, Y))\r\n",
      "   292     57.6 MiB      0.0 MiB               D = np.diag(R.diagonal())\r\n",
      "   293     58.1 MiB      0.0 MiB           assert D[-1,-1] > 0, \"k = {}: \".format(k)  # Assumption of Theorem 2.2\r\n",
      "   294                             \r\n",
      "   295     58.1 MiB      0.0 MiB           if k > maxcor:\r\n",
      "   296     58.1 MiB      0.0 MiB               YTY = np.roll(YTY, (-1, -1), axis=(0, 1))\r\n",
      "   297     58.1 MiB      0.0 MiB               YTY[-1, :-1] = YTY[:-1, -1] = (YTgrad[:-1] - YTgrad_prev[1:]).flat\r\n",
      "   298     58.1 MiB      0.0 MiB               YTY[-1, -1] = grad2prev - grad2 + 2 * YTgrad[-1]\r\n",
      "   299                                     else:\r\n",
      "   300                                         #YTYm = pnp.dot(Y.T, Y)\r\n",
      "   301     57.6 MiB      0.0 MiB               YTY = np.array([[pnp.dot(yi1.T, yi2).item() for yi2 in Ylist] for yi1 in Ylist])\r\n",
      "   302                                     # Step 5.\r\n",
      "   303     58.1 MiB      0.0 MiB           gamma = D[-1, -1] / YTY[-1, -1]  # n.b. D[-1,-1] = sk-1T yk-1 = yk-1T sk-1\r\n",
      "   304                             \r\n",
      "   305                                     # Step 6. and 7. together\r\n",
      "   306     58.1 MiB      0.1 MiB           Rinv = np.linalg.inv(R)\r\n",
      "   307     58.1 MiB      0.0 MiB           RiSg = Rinv.dot(STgrad)\r\n",
      "   308     58.1 MiB      0.0 MiB           p1 = Rinv.T.dot(D + gamma * YTY).dot(RiSg) - gamma * Rinv.T.dot(YTgrad)\r\n",
      "   309     58.1 MiB      0.0 MiB           p2 = - RiSg #TODO\r\n",
      "   310                             \r\n",
      "   311                                     #temphstack=np.hstack([S, gamma * Y])\r\n",
      "   312                             \r\n",
      "   313                                     #Hgradm = gamma * grad + S.dot(p1)  + gamma * Y.dot(p2)\r\n",
      "   314     58.1 MiB      0.0 MiB           Hgrad = gamma * grad\r\n",
      "   315     58.1 MiB      0.0 MiB           for si, yi, p1i, p2i in zip(Slist, Ylist, p1.flat, p2.flat):\r\n",
      "   316     58.1 MiB      0.1 MiB               Hgrad += si * p1i.item() + gamma * yi * p2i.item()\r\n",
      "   317                             \r\n",
      "   318     58.1 MiB      0.0 MiB           phi_old = float(phi)\r\n",
      "   319                                     #printdb(\"Linesearch: \")\r\n",
      "   320     58.1 MiB      0.0 MiB           grad_old[:] = grad\r\n",
      "   321     58.1 MiB      0.0 MiB           x_old[:] = x\r\n",
      "   322     58.1 MiB      0.0 MiB           def _phi_phiprime(alpha):\r\n",
      "   323     58.1 MiB      0.0 MiB               phi, grad[...] = fun_grad(x - Hgrad * alpha)\r\n",
      "   324     58.1 MiB      0.0 MiB               phiprime = pnp.dot(grad.T, -Hgrad).item()\r\n",
      "   325     58.1 MiB      0.0 MiB               return phi, phiprime\r\n",
      "   326                             \r\n",
      "   327                                     #TODO: oldphi0: is it allowed to stay outside of the search direction ?\r\n",
      "   328     58.1 MiB      0.0 MiB           alpha, phi, phi0, derphi = scalar_search_wolfe2(_phi_phiprime, phi0=phi,\r\n",
      "   329     58.1 MiB      0.0 MiB                                                           derphi0=pnp.dot(grad.T, -Hgrad).item(), maxiter=maxls, **linesearch_options)\r\n",
      "   330                             \r\n",
      "   331     58.1 MiB      0.0 MiB           printdb(\"derphi: {}\".format(derphi))\r\n",
      "   332     58.1 MiB      0.0 MiB           assert derphi is not None, \"line-search did not converge\"\r\n",
      "   333                             \r\n",
      "   334                             \r\n",
      "   335     58.1 MiB      0.0 MiB           x = x - Hgrad * alpha\r\n",
      "   336                             \r\n",
      "   337     58.1 MiB      0.0 MiB           if store_iterates == 'iterate':\r\n",
      "   338                                         iterate = scipy.optimize.OptimizeResult(\r\n",
      "   339                                             {'x': x.copy().reshape(original_shape),\r\n",
      "   340                                              'fun': phi,\r\n",
      "   341                                              'jac': grad.reshape(original_shape)})\r\n",
      "   342                                         iterates.append(iterate)\r\n",
      "   343                             \r\n",
      "   344     58.1 MiB      0.0 MiB           printdb(\"k = {}\".format(k))\r\n",
      "   345     58.1 MiB      0.0 MiB           k = k + 1\r\n",
      "   346                             \r\n",
      "   347     58.1 MiB      0.0 MiB           STgrad_prev = STgrad.copy()\r\n",
      "   348     58.1 MiB      0.0 MiB           YTgrad_prev = YTgrad.copy()\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat {fn} | sed \"/^[0-9]/p \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 15 fields in line 5, saw 31\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-2962b2ec078d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, path, header, sep, index_col, parse_dates, encoding, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m   1577\u001b[0m                           \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m                           \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtupleize_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m                           infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.open_topography\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 15 fields in line 5, saw 31\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.from_csv(fn, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/antoines/NuMPI/helpers\n"
     ]
    }
   ],
   "source": [
    "%cd helpers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%script sh --err ERR --out OUT\n",
    "rm *.log\n",
    "cd ..\n",
    "source env.sh\n",
    "cd helpers\n",
    "mpirun -np 2 python memoryprofiling_LBFGS.py 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'D=$PWD;cd ../../;source env.sh;cd $D;mpirun -np 2 python memoryprofiling_LBFGS.py 10000' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c71e02669207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                  \u001b[0;34m\"source env.sh;\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0;34m\"cd $D;\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                  \"mpirun -np 2 python memoryprofiling_LBFGS.py 10000\",shell=True, timeout=120,stderr=subprocess.STDOUT ).decode()\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 376\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 468\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'D=$PWD;cd ../../;source env.sh;cd $D;mpirun -np 2 python memoryprofiling_LBFGS.py 10000' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "output = subprocess.check_output(\"D=$PWD;\"\n",
    "                                 \"cd ../../;\"\n",
    "                                 \"source env.sh;\"\n",
    "                                 \"cd $D;\"\n",
    "                                 \"mpirun -np 2 python memoryprofiling_LBFGS.py 10000\",shell=True, timeout=120,stderr=subprocess.STDOUT ).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-61353e8b2d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS_Matrix_H_Verbose.py\r\n",
      "LBFGS_Matrix_Hk.ipynb\r\n",
      "LBFGS_Matrix_Hk_Opt1.ipynb\r\n",
      "LBFGS_iterative.ipynb\r\n",
      "LBFGS_memory_profile_n10000_nprocs2_rank0.log\r\n",
      "LBFGS_memory_profile_n10000_nprocs2_rank1.log\r\n",
      "Memory profiling LBFGS line by line.ipynb\r\n",
      "Numpy Matrix Operations.ipynb\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m/\r\n",
      "copyright.py\r\n",
      "learn_scipy_linesearch.py\r\n",
      "line_profiing_LBFGSB.ipynb\r\n",
      "memoryprofiling_LBFGS.py\r\n",
      "nb_fevals_scipy_vs_numpy.py\r\n",
      "plot_helpers.py\r\n",
      "profiling.py\r\n",
      "replace_header.py\r\n",
      "solve_Rosenbrock.py\r\n",
      "temp_LBFGS_performance_test.py\r\n",
      "timing basic numpy operations.ipynb\r\n",
      "update_license_headers.sh\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sublime LBFGS_memory_profile_n1000_nprocs2_rank0.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
